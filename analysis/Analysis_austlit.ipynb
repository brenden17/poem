{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch articles\n",
    "\n",
    "* poems : fetched poems from search with \"poem\" tag - http://trove.nla.gov.au/newspaper/result?l-publictag=poem&q&s=20 (get_poem.py), saved in /data/poems-201604022338.csv\n",
    "* other article : fetched others in random from 'http://trove.nla.gov.au/newspaper/article/11XXX999', saved in data/others-201604030052.csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "poems = pd.read_csv('../data/poem-austlit-20160412.csv')\n",
    "poems.head()\n",
    "poems.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate signals(features)\n",
    "\n",
    "convert lines, words, x, y, w, h in html input tag into singals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_line(contents):\n",
    "    if not contents: \n",
    "        return 0\n",
    "    lines = contents.split('\\n')\n",
    "    return len(lines)\n",
    "\n",
    "def mean_word(contents):\n",
    "    if not contents: \n",
    "        return 0\n",
    "    lines = contents.split('\\n')\n",
    "    words = [len(line.split(' ')) for line in lines]\n",
    "    return np.mean(words)\n",
    "\n",
    "def total_word(contents):\n",
    "    if not contents:\n",
    "        return 0\n",
    "    lines = contents.split('\\n')\n",
    "    words = [len(line.split(' ')) for line in lines]\n",
    "    return sum(words)\n",
    "\n",
    "def std_w(data_w):\n",
    "    if not data_w:\n",
    "        return 0\n",
    "    ws = map(int, data_w.split(','))\n",
    "    return np.std(ws)\n",
    "\n",
    "def mean_y(data_y):\n",
    "    if not data_y:\n",
    "        return 0\n",
    "    ys = map(int, data_y.split(','))\n",
    "    return np.mean([abs(ys[1:][i] - ys[:-1][i]) for i in range(0, len(ys[1:]))])\n",
    "\n",
    "def mean_h(data_h):\n",
    "    if not data_h:\n",
    "        return 0\n",
    "    hs = map(int, data_h.split(','))\n",
    "    return np.mean(hs)\n",
    "\n",
    "def mean_x(data_x):\n",
    "    if not data_x:\n",
    "        return 0\n",
    "    xs = map(int, data_x.split(','))\n",
    "    x_min = np.min(xs)\n",
    "    return np.mean(map(lambda x:x-x_min, xs))\n",
    "\n",
    "def get_page(page):\n",
    "    return int(page.replace('Page', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_feature(df, target=1):\n",
    "    df['count_line'] = df['content'].apply(count_line)\n",
    "    df['mean_word'] = df['content'].apply(mean_word)\n",
    "    df['total_word'] = df['content'].apply(total_word)\n",
    "    df['std_w'] = df['data_w'].apply(std_w)\n",
    "    df['mean_y'] = df['data_y'].apply(mean_y)\n",
    "    df['mean_h'] = df['data_h'].apply(mean_h)\n",
    "    df['mean_x'] = df['data_x'].apply(mean_x)\n",
    "    df['page_num'] = df['page'].apply(get_page)\n",
    "    df['target'] = target\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>data_h</th>\n",
       "      <th>content</th>\n",
       "      <th>newspaper</th>\n",
       "      <th>data_w</th>\n",
       "      <th>date</th>\n",
       "      <th>data_y</th>\n",
       "      <th>data_x</th>\n",
       "      <th>article_id</th>\n",
       "      <th>page</th>\n",
       "      <th>count_line</th>\n",
       "      <th>mean_word</th>\n",
       "      <th>total_word</th>\n",
       "      <th>std_w</th>\n",
       "      <th>mean_y</th>\n",
       "      <th>mean_h</th>\n",
       "      <th>mean_x</th>\n",
       "      <th>page_num</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Poets Corner</td>\n",
       "      <td>144,308,78,30,42,36,36,39,37,40,38,36,38,38,39...</td>\n",
       "      <td>^^^i\\ne^5\\nLu ? r\\nMAD POETS.\\nf1' Some people...</td>\n",
       "      <td>The Central Queensland Herald</td>\n",
       "      <td>349,576,451,249,669,713,474,588,476,489,390,65...</td>\n",
       "      <td>Thu 2 Jan 1936</td>\n",
       "      <td>788,484,740,1048,1099,1139,1180,1232,1272,1310...</td>\n",
       "      <td>264,912,912,284,96,50,53,51,89,53,93,54,94,54,...</td>\n",
       "      <td>70348715</td>\n",
       "      <td>Page 8</td>\n",
       "      <td>48</td>\n",
       "      <td>5.729167</td>\n",
       "      <td>275</td>\n",
       "      <td>108.055636</td>\n",
       "      <td>59.340426</td>\n",
       "      <td>46.583333</td>\n",
       "      <td>87.979167</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CORRESPONDENCE</td>\n",
       "      <td>61,61,48,39,32,43,39,41,38,39,33,39,36,40,39,4...</td>\n",
       "      <td>CORRESPONDENCE\\nVALE OPOSSUM^; :' ' ;':\\n(To t...</td>\n",
       "      <td>The Central Queensland Herald</td>\n",
       "      <td>505,454,370,679,439,679,498,679,255,677,411,67...</td>\n",
       "      <td>Thu 23 Jul 1931</td>\n",
       "      <td>3185,3333,3455,3532,3573,3609,3652,3690,3730,3...</td>\n",
       "      <td>1195,1278,1294,1122,1197,1124,1160,1121,1196,1...</td>\n",
       "      <td>70280540</td>\n",
       "      <td>Page 47</td>\n",
       "      <td>45</td>\n",
       "      <td>4.711111</td>\n",
       "      <td>212</td>\n",
       "      <td>165.352278</td>\n",
       "      <td>49.795455</td>\n",
       "      <td>39.355556</td>\n",
       "      <td>76.600000</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Worshipper.</td>\n",
       "      <td>55,37,40,32,34,30,30,35,35,35,28,30,34,30,32,2...</td>\n",
       "      <td>The Worshipper.\\nI WOULD not nurse a lovely th...</td>\n",
       "      <td>The Brisbane Courier</td>\n",
       "      <td>355,621,164,438,618,257,427,614,583,616,166,46...</td>\n",
       "      <td>Sat 4 Jan 1930</td>\n",
       "      <td>5315,5462,5486,5523,5553,5584,5613,5670,5700,5...</td>\n",
       "      <td>535,396,396,430,397,492,427,398,429,399,492,42...</td>\n",
       "      <td>21502619</td>\n",
       "      <td>Page 20</td>\n",
       "      <td>45</td>\n",
       "      <td>4.844444</td>\n",
       "      <td>218</td>\n",
       "      <td>185.748929</td>\n",
       "      <td>37.045455</td>\n",
       "      <td>32.333333</td>\n",
       "      <td>43.200000</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>THE LOST MERCHANT.</td>\n",
       "      <td>41,56,35,29,28,26,27,26,27,25,26,25,27,26,25,2...</td>\n",
       "      <td>TUB LOST MKRCHAXT. I\\nOa \" HOPES THAT ARE BRIG...</td>\n",
       "      <td>Empire</td>\n",
       "      <td>795,1006,927,896,890,519,605,561,602,522,570,5...</td>\n",
       "      <td>Sat 30 Jun 1860</td>\n",
       "      <td>1243,1286,1343,1373,1397,1424,1448,1472,1495,1...</td>\n",
       "      <td>5000,4789,4869,4869,4871,4871,4873,4869,4870,4...</td>\n",
       "      <td>60412555</td>\n",
       "      <td>Page 4</td>\n",
       "      <td>60</td>\n",
       "      <td>7.816667</td>\n",
       "      <td>469</td>\n",
       "      <td>126.620969</td>\n",
       "      <td>25.152542</td>\n",
       "      <td>27.116667</td>\n",
       "      <td>93.200000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENIGMA.—No. IV.</td>\n",
       "      <td>32,38,36,37,38,32,38,38,37,35,38,39,41,37,33,3...</td>\n",
       "      <td>ENIGMA.— No. IV.\\nI liave a dear partner for l...</td>\n",
       "      <td>Bathurst Free Press</td>\n",
       "      <td>320,471,556,591,650,412,570,577,687,443,550,55...</td>\n",
       "      <td>Sat 21 Sep 1850</td>\n",
       "      <td>3425,3491,3522,3554,3584,3653,3682,3714,3746,3...</td>\n",
       "      <td>633,423,458,425,458,420,450,424,458,422,457,41...</td>\n",
       "      <td>62215013</td>\n",
       "      <td>Page 6</td>\n",
       "      <td>20</td>\n",
       "      <td>6.350000</td>\n",
       "      <td>127</td>\n",
       "      <td>118.589744</td>\n",
       "      <td>42.157895</td>\n",
       "      <td>38.400000</td>\n",
       "      <td>100.950000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                title                                             data_h  \\\n",
       "0        Poets Corner  144,308,78,30,42,36,36,39,37,40,38,36,38,38,39...   \n",
       "1      CORRESPONDENCE  61,61,48,39,32,43,39,41,38,39,33,39,36,40,39,4...   \n",
       "2     The Worshipper.  55,37,40,32,34,30,30,35,35,35,28,30,34,30,32,2...   \n",
       "3  THE LOST MERCHANT.  41,56,35,29,28,26,27,26,27,25,26,25,27,26,25,2...   \n",
       "4     ENIGMA.—No. IV.  32,38,36,37,38,32,38,38,37,35,38,39,41,37,33,3...   \n",
       "\n",
       "                                             content  \\\n",
       "0  ^^^i\\ne^5\\nLu ? r\\nMAD POETS.\\nf1' Some people...   \n",
       "1  CORRESPONDENCE\\nVALE OPOSSUM^; :' ' ;':\\n(To t...   \n",
       "2  The Worshipper.\\nI WOULD not nurse a lovely th...   \n",
       "3  TUB LOST MKRCHAXT. I\\nOa \" HOPES THAT ARE BRIG...   \n",
       "4  ENIGMA.— No. IV.\\nI liave a dear partner for l...   \n",
       "\n",
       "                        newspaper  \\\n",
       "0  The Central Queensland Herald    \n",
       "1  The Central Queensland Herald    \n",
       "2           The Brisbane Courier    \n",
       "3                         Empire    \n",
       "4            Bathurst Free Press    \n",
       "\n",
       "                                              data_w             date  \\\n",
       "0  349,576,451,249,669,713,474,588,476,489,390,65...   Thu 2 Jan 1936   \n",
       "1  505,454,370,679,439,679,498,679,255,677,411,67...  Thu 23 Jul 1931   \n",
       "2  355,621,164,438,618,257,427,614,583,616,166,46...   Sat 4 Jan 1930   \n",
       "3  795,1006,927,896,890,519,605,561,602,522,570,5...  Sat 30 Jun 1860   \n",
       "4  320,471,556,591,650,412,570,577,687,443,550,55...  Sat 21 Sep 1850   \n",
       "\n",
       "                                              data_y  \\\n",
       "0  788,484,740,1048,1099,1139,1180,1232,1272,1310...   \n",
       "1  3185,3333,3455,3532,3573,3609,3652,3690,3730,3...   \n",
       "2  5315,5462,5486,5523,5553,5584,5613,5670,5700,5...   \n",
       "3  1243,1286,1343,1373,1397,1424,1448,1472,1495,1...   \n",
       "4  3425,3491,3522,3554,3584,3653,3682,3714,3746,3...   \n",
       "\n",
       "                                              data_x  article_id     page  \\\n",
       "0  264,912,912,284,96,50,53,51,89,53,93,54,94,54,...    70348715   Page 8   \n",
       "1  1195,1278,1294,1122,1197,1124,1160,1121,1196,1...    70280540  Page 47   \n",
       "2  535,396,396,430,397,492,427,398,429,399,492,42...    21502619  Page 20   \n",
       "3  5000,4789,4869,4869,4871,4871,4873,4869,4870,4...    60412555   Page 4   \n",
       "4  633,423,458,425,458,420,450,424,458,422,457,41...    62215013   Page 6   \n",
       "\n",
       "   count_line  mean_word  total_word       std_w     mean_y     mean_h  \\\n",
       "0          48   5.729167         275  108.055636  59.340426  46.583333   \n",
       "1          45   4.711111         212  165.352278  49.795455  39.355556   \n",
       "2          45   4.844444         218  185.748929  37.045455  32.333333   \n",
       "3          60   7.816667         469  126.620969  25.152542  27.116667   \n",
       "4          20   6.350000         127  118.589744  42.157895  38.400000   \n",
       "\n",
       "       mean_x  page_num  target  \n",
       "0   87.979167         8       1  \n",
       "1   76.600000        47       1  \n",
       "2   43.200000        20       1  \n",
       "3   93.200000         4       1  \n",
       "4  100.950000         6       1  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_feature(poems)\n",
    "print poem.shape\n",
    "poems.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read other articles & generate signals(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(493, 19)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# others\n",
    "others = pd.read_csv('../data/others-201604120925.csv')\n",
    "convert_feature(others, target=0)\n",
    "others.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch signals(features) before applying algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['count_line', 'mean_word', 'total_word', 'std_w', 'mean_y', 'mean_h', 'mean_x', 'page_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other_x = others[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other_x[other_x > 1000] = 1000\n",
    "other_x[np.isnan(other_x)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "poem_x = poems[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((other_x, poem_x), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "other_y = others[['target']].values\n",
    "poem_y = poems[['target']].values\n",
    "y = np.concatenate((other_y, poem_y), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(993L, 8L) (993L,)\n"
     ]
    }
   ],
   "source": [
    "y = y.flatten()\n",
    "print X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn import decomposition\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying different algoriths with only newspaper format signal to check  accurcy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Applying SVC Classifier(Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.58 (+/- 0.13)\n"
     ]
    }
   ],
   "source": [
    "svc = SGDClassifier()\n",
    "svc.fit(X, y)\n",
    "scores = cross_val_score(svc, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Appliying Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91 (+/- 0.01)\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest.fit(X, y)\n",
    "scores = cross_val_score(forest, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Appliying Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.80 (+/- 0.06)\n"
     ]
    }
   ],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X, y)\n",
    "scores = cross_val_score(logistic, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Appliying Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64 (+/- 0.09)\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X, y)\n",
    "scores = cross_val_score(nb, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimization in Random Forest Classifier which is the best classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Score : ', 0.93353474320241692)\n",
      "clf__criterion: 'gini'\n",
      "clf__max_features: 'auto'\n",
      "clf__n_estimators: 70\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([#('pca', PCA()),\n",
    "                    ('clf', RandomForestClassifier()),\n",
    "                ])\n",
    "\n",
    "parameters = {#'pca__n_components': (3, 4, 5, 6, 7),\n",
    "                'clf__n_estimators': (5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70), \n",
    "                'clf__criterion': ('gini', 'entropy'),\n",
    "                'clf__max_features': ('auto', 'sqrt', 'log2')\n",
    "             }    \n",
    "\n",
    "gs_clf = GridSearchCV(clf, parameters, cv=5)\n",
    "gs_clf.fit(X, y)\n",
    "\n",
    "best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "print('Score : ', score)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find important singals  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.2245, 'page_num'), (0.1505, 'mean_y'), (0.1357, 'mean_h'), (0.1252, 'mean_word'), (0.1182, 'total_word'), (0.0954, 'count_line'), (0.0934, 'mean_x'), (0.0573, 'std_w')]\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50, max_features='sqrt', criterion='gini')\n",
    "clf.fit(X, y)\n",
    "\n",
    "print sorted(zip(map(lambda x: round(x, 4), clf.feature_importances_), features), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best signals\n",
    "\n",
    "1. mean word per line\n",
    "1. newspaper page number\n",
    "1. indent x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Naive Bayes algorithm on poem and other articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((poems['content'].values, others['content'].values), axis=0)\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=10, min_df=1)\n",
    "X = vectorizer.fit_transform(X)\n",
    "X = TfidfTransformer().fit_transform(X)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.91 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X, y)\n",
    "\n",
    "scores = cross_val_score(nb, X, y, cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Score : ', 0.91339375629405839)\n",
      "clf__alpha: 1\n",
      "clf__fit_prior: True\n"
     ]
    }
   ],
   "source": [
    "clf = Pipeline([\n",
    "#                 ('vect', CountVectorizer()),\n",
    "#                 ('tfidf', TfidfTransformer()),\n",
    "                ('clf', MultinomialNB()),\n",
    "            ])\n",
    "    \n",
    "parameters = {\n",
    "#                 'tfidf__use_idf': (True, False),\n",
    "                'clf__alpha': (0,1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4), \n",
    "                'clf__fit_prior':(True, False)}    \n",
    "    \n",
    "    \n",
    "gs_clf = GridSearchCV(clf, parameters, cv=5)\n",
    "\n",
    "gs_clf.fit(X, y)\n",
    "\n",
    "best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "print('Score : ', score)\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine the two best classifiers(RandomForest classifier on newspaper format and Naive Bayes on Content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "\n",
    "import numpy as np\n",
    "import operator\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, classifiers, weights=None):\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {key: value for key, value in _name_estimators(classifiers)}\n",
    "        print(self.named_classifiers)\n",
    "        self.weights = weights\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            \n",
    "            fitted_clf = clone(clf).fit(X, y)\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        probas = np.asarray([cls.predict_proba(X) for clf in self.classifiers_])\n",
    "        avg_proba = np.average(probas, axis=0, weights=self.weights)\n",
    "        return avg_proba\n",
    "    \n",
    "    def get_params(self, deep=True):\n",
    "        if not deep:\n",
    "            return super(MajorityVoteClassifier, self).get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in six.iteritems(self.named_classifiers):\n",
    "                for key, value in six.iteritems(step.get_params(deep=True)):\n",
    "                    out['%s__%s' % (name, key)] = value\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
