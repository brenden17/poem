{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## signals(features)\n",
    "\n",
    "convert lines, words, x, y, w, h in html input tag into singals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_line(contents):\n",
    "    if not contents: \n",
    "        return 0\n",
    "    lines = contents.split('\\n')\n",
    "    return len(lines)\n",
    "\n",
    "def mean_word(contents):\n",
    "    if not contents: \n",
    "        return 0\n",
    "    lines = contents.split('\\n')\n",
    "    words = [len(line.split(' ')) for line in lines]\n",
    "    return np.mean(words)\n",
    "\n",
    "def total_word(contents):\n",
    "    if not contents:\n",
    "        return 0\n",
    "    lines = contents.split('\\n')\n",
    "    words = [len(line.split(' ')) for line in lines]\n",
    "    return sum(words)\n",
    "\n",
    "def std_w(data_w):\n",
    "    if not data_w:\n",
    "        return 0\n",
    "    ws = map(int, data_w.split(','))\n",
    "    return np.std(ws)\n",
    "\n",
    "def mean_y(data_y):\n",
    "    if not data_y:\n",
    "        return 0\n",
    "    ys = map(int, data_y.split(','))\n",
    "    return np.mean([abs(ys[1:][i] - ys[:-1][i]) for i in range(0, len(ys[1:]))])\n",
    "\n",
    "def mean_h(data_h):\n",
    "    if not data_h:\n",
    "        return 0\n",
    "    hs = map(int, data_h.split(','))\n",
    "    return np.mean(hs)\n",
    "\n",
    "def mean_x(data_x):\n",
    "    if not data_x:\n",
    "        return 0\n",
    "    xs = map(int, data_x.split(','))\n",
    "    x_min = np.min(xs)\n",
    "    return np.mean(map(lambda x:x-x_min, xs))\n",
    "\n",
    "def get_page(page):\n",
    "    return int(page.replace('Page', '').strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_feature(df, target=1):\n",
    "    df['count_line'] = df['content'].apply(count_line)\n",
    "    df['mean_word'] = df['content'].apply(mean_word)\n",
    "    df['total_word'] = df['content'].apply(total_word)\n",
    "    df['std_w'] = df['data_w'].apply(std_w)\n",
    "    df['mean_y'] = df['data_y'].apply(mean_y)\n",
    "    df['mean_h'] = df['data_h'].apply(mean_h)\n",
    "    df['mean_x'] = df['data_x'].apply(mean_x)\n",
    "    df['page_num'] = df['page'].apply(get_page)\n",
    "    df['target'] = target\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read poem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 19)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "poems = pd.read_csv('../data/poem-austlit-20160412.csv')\n",
    "convert_feature(poems, target=1)\n",
    "print poems.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(493, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/dev/workspace/word2vec/dist/local/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# others\n",
    "others = pd.read_csv('../data/others-201604120925.csv')\n",
    "convert_feature(others, target=0)\n",
    "print others.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_df = pd.concat([poems, others])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(993, 19)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.cross_validation import cross_val_score, KFold, train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.externals import six\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MajorityVoteClassifier(object):\n",
    "    def __init__(self):\n",
    "        self.classifiers = []\n",
    "        self.poem_filename = '../data/poem-austlit-20160412.csv'\n",
    "        self.other_filename = '../data/others-201604120925.csv'\n",
    "\n",
    "    def read_all(self):\n",
    "        poems = pd.read_csv(self.poem_filename)\n",
    "        convert_feature(poems, target=1)\n",
    "        \n",
    "        others = pd.read_csv(self.other_filename)\n",
    "        convert_feature(others, target=0)\n",
    "        \n",
    "        self.all_df = pd.concat([poems, others])\n",
    "        \n",
    "    def process_all(self):\n",
    "        format_features = ['count_line', 'mean_word', 'total_word', 'std_w', 'mean_y', 'mean_h', 'mean_x', 'page_num']\n",
    "        content_features = 'content'\n",
    "        y_feature = 'target'\n",
    "        \n",
    "        X_format = self.all_df[format_features].values\n",
    "        X_format[X_format > 1000] = 1000\n",
    "        X_format[np.isnan(X_format)] = 0\n",
    "        \n",
    "        X_content = self.all_df[content_features].values\n",
    "        X_content = CountVectorizer(max_df=10, min_df=1).fit_transform(X_content)\n",
    "        X_content = TfidfTransformer().fit_transform(X_content)\n",
    "        \n",
    "        y = self.all_df[y_feature].values\n",
    "        y = y.flatten()\n",
    "        \n",
    "        self.X_format_train, self.X_format_test, self.y_format_train, self.y_format_test = train_test_split(X_format, y, test_size=0.20, random_state=42)\n",
    "        self.X_content_train, self.X_content_test, self.y_content_train, self.y_content_test = train_test_split(X_content, y, test_size=0.20, random_state=42)\n",
    "    \n",
    "    def process(self, df):\n",
    "        print(df)\n",
    "        format_features = ['count_line', 'mean_word', 'total_word', 'std_w', 'mean_y', 'mean_h', 'mean_x', 'page_num']\n",
    "        content_features = ['content']\n",
    "        y_feature = 'target'\n",
    "        \n",
    "        X_format = df[format_features].values\n",
    "        X_format[X_format > 1000] = 1000\n",
    "#         X_format[np.isnan(X_format)] = 0\n",
    "        \n",
    "        X_content = df[content_features].values\n",
    "        X_content = CountVectorizer(max_df=10, min_df=1).fit_transform(X_content)\n",
    "        X_content = TfidfTransformer().fit_transform(X_content)\n",
    "        return X_format, X_content\n",
    "        \n",
    "        \n",
    "    def predict(self):\n",
    "        count = len(self.y_content_test)\n",
    "        predictions = [self._predict(self.X_format_test[i, :], self.X_content_test[i, :]) for i in range(0, count)]\n",
    "        predictions = np.array(predictions)\n",
    "        \n",
    "        print(sum(predictions==self.y_content_test)/count)\n",
    "        return sum(predictions==self.y_content_test)/count\n",
    "    \n",
    "    def _predict(self, X_format, X_content):\n",
    "        return self.predict_proba(X_format, X_content)\n",
    "    \n",
    "    def predict_proba(self, X_format, X_content):\n",
    "        probas = []\n",
    "        predicts = []\n",
    "        for name, clf in self.classifiers:\n",
    "            if name == 'RandomForest':\n",
    "                X = X_format\n",
    "            else:\n",
    "                X = X_content\n",
    "            probas.append(clf.predict_proba(X))\n",
    "            predicts.append(clf.predict(X))\n",
    "            \n",
    "        probas = np.asarray(probas)\n",
    "        n = np.argmax(probas)\n",
    "        if n in [0, 1]:\n",
    "            return predicts[0][0]\n",
    "        elif n in [2, 3]:\n",
    "            return predicts[1][0]\n",
    "        else:\n",
    "            return predicts[2][0]\n",
    "    \n",
    "    def export(self):\n",
    "        count = 2\n",
    "        small_df = self.all_df.sample(n=count)\n",
    "        for i in range(0, count):\n",
    "            poem_df = small_df.iloc[i]\n",
    "            X_format, X_content = self.process(poem_df)\n",
    "            predictions = self._predict(X_format, X_content)\n",
    "            \n",
    "            yield {'title': poem_df['title'],\n",
    "                   'slug': poem_df['article_id'],\n",
    "                   'newspaper': poem_df['newspaper'],\n",
    "                   'page': poem_df['page'].replace('Page', '').strip(),\n",
    "                   'content': poem_df['content'],\n",
    "                   'prediction': poem_df['prediction']}\n",
    "            \n",
    "    def run(self):\n",
    "        print('read **************************************')\n",
    "        self.read_all()\n",
    "        print('process_data ******************************')\n",
    "        self.process_all()\n",
    "        print('train_classifier **************************')\n",
    "        self.triain_rfclassifier()\n",
    "        self.triain_nbclassifier()\n",
    "        self.triain_lrclassifier()\n",
    "        print('predict ***********************************')\n",
    "        print self.predict()\n",
    "        \n",
    "    def triain_rfclassifier(self):\n",
    "        X, y = self.X_format_train, self.y_format_train\n",
    "        clf = Pipeline([\n",
    "                    ('clf', RandomForestClassifier()),\n",
    "                ])\n",
    "\n",
    "        parameters = {\n",
    "#                         'clf__n_estimators': (5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 60, 70), \n",
    "#                         'clf__criterion': ('gini', 'entropy'),\n",
    "#                         'clf__max_features': ('auto', 'sqrt', 'log2')\n",
    "                     }    \n",
    "\n",
    "        gs_clf = GridSearchCV(clf, parameters, cv=5)\n",
    "        gs_clf.fit(X, y)\n",
    "\n",
    "        best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "        print('RandomForestClassifier')\n",
    "        print('Score : ', score)\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "        self.classifiers.append(('RandomForest', gs_clf.best_estimator_))\n",
    "    \n",
    "    def triain_nbclassifier(self):\n",
    "        X, y = self.X_content_train, self.y_content_train\n",
    "        \n",
    "        clf = Pipeline([\n",
    "                        ('clf', MultinomialNB()),\n",
    "                    ])\n",
    "\n",
    "        parameters = { 'clf__alpha': (0,1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4), \n",
    "                        'clf__fit_prior':(True, False)}    \n",
    "\n",
    "        gs_clf = GridSearchCV(clf, parameters, cv=5)\n",
    "        gs_clf.fit(X, y)\n",
    "\n",
    "        best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "        print('MultinomialNB')\n",
    "        print('Score : ', score)\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "        self.classifiers.append(('MultinomialNB', gs_clf.best_estimator_))\n",
    "    \n",
    "    def triain_lrclassifier(self):\n",
    "        X, y = self.X_content_train, self.y_content_train\n",
    "        \n",
    "        clf = Pipeline([\n",
    "                        ('clf', LogisticRegression()),\n",
    "                    ])\n",
    "\n",
    "        parameters = { \n",
    "#                         'clf__alpha': (0,1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.1, 1.2, 1.3, 1.4), \n",
    "#                         'clf__fit_prior':(True, False)\n",
    "                     }    \n",
    "\n",
    "        gs_clf = GridSearchCV(clf, parameters, cv=5)\n",
    "        gs_clf.fit(X, y)\n",
    "\n",
    "        best_parameters, score, _ = max(gs_clf.grid_scores_, key=lambda x: x[1])\n",
    "        print('LogisticRegressionClassifier')\n",
    "        print('Score : ', score)\n",
    "        for param_name in sorted(parameters.keys()):\n",
    "            print(\"%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "        self.classifiers.append(('LogisticRegression', gs_clf.best_estimator_))\n",
    "    \n",
    "    def save(self):\n",
    "        joblib.dump(clf, 'filename.pkl') \n",
    "        joblib.dump(clf, 'filename.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read **************************************\n",
      "process_data ******************************\n",
      "train_classifier **************************\n",
      "RandomForestClassifier\n",
      "('Score : ', 0.89294710327455917)\n",
      "MultinomialNB\n",
      "('Score : ', 0.88539042821158687)\n",
      "clf__alpha: 0.3\n",
      "clf__fit_prior: False\n",
      "LogisticRegressionClassifier\n",
      "('Score : ', 0.92695214105793455)\n",
      "predict ***********************************\n",
      "0.904522613065\n",
      "0.904522613065\n",
      "title                                                LITERATURE\n",
      "data_h        2,94,33,19,27,36,31,33,33,33,36,34,33,28,31,33...\n",
      "content       LITERATURE\\nOriginal Poetry.\\nAmor Anni\\nIN EN...\n",
      "newspaper                                     The Queenslander \n",
      "data_w        858,490,289,210,279,268,467,340,470,365,335,38...\n",
      "date                                            Sat 19 Nov 1881\n",
      "data_y        306,591,728,784,1586,849,882,915,946,1003,1038...\n",
      "data_x        220,387,498,537,770,359,359,359,357,359,357,35...\n",
      "article_id                                             20711103\n",
      "page                                                   Page 649\n",
      "count_line                                                   25\n",
      "mean_word                                                  3.72\n",
      "total_word                                                   93\n",
      "std_w                                                   127.269\n",
      "mean_y                                                  112.708\n",
      "mean_h                                                    33.24\n",
      "mean_x                                                   162.36\n",
      "page_num                                                    649\n",
      "target                                                        1\n",
      "Name: 134, dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "dimension mismatch",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-1a79dcd09ba6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmvc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMajorityVoteClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmvc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-73079512114e>\u001b[0m in \u001b[0;36mexport\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mpoem_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmall_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mX_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_content\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoem_df\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m             yield {'title': poem_df['title'],\n",
      "\u001b[1;32m<ipython-input-22-73079512114e>\u001b[0m in \u001b[0;36m_predict\u001b[1;34m(self, X_format, X_content)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_format\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-22-73079512114e>\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X_format, X_content)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_content\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[0mprobas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[0mpredicts\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/dev/workspace/word2vec/dist/local/lib/python2.7/site-packages/sklearn/utils/metaestimators.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_attribute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# lambda, but not partial, allows help() to work with update_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m         \u001b[1;31m# update the docstring of the returned function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[0mupdate_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/dev/workspace/word2vec/dist/local/lib/python2.7/site-packages/sklearn/pipeline.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'_final_estimator'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/dev/workspace/word2vec/dist/local/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    101\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mappear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \"\"\"\n\u001b[1;32m--> 103\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_log_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/dev/workspace/word2vec/dist/local/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mpredict_log_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mappear\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;33m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \"\"\"\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mjll\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[1;31m# normalize by P(x) = P(f_1, ..., f_n)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[0mlog_prob_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/dev/workspace/word2vec/dist/local/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    671\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 672\u001b[1;33m         return (safe_sparse_dot(X, self.feature_log_prob_.T)\n\u001b[0m\u001b[0;32m    673\u001b[0m                 + self.class_log_prior_)\n\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/dev/workspace/word2vec/dist/local/lib/python2.7/site-packages/sklearn/utils/extmath.pyc\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \"\"\"\n\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdense_output\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"toarray\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/mnt/dev/workspace/word2vec/dist/local/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    356\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: dimension mismatch"
     ]
    }
   ],
   "source": [
    "mvc = MajorityVoteClassifier()\n",
    "mvc.run()\n",
    "for i in mvc.export():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
